{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70203,"databundleVersionId":8068726,"sourceType":"competition"},{"sourceId":7402356,"sourceType":"datasetVersion","datasetId":4304475},{"sourceId":8588338,"sourceType":"datasetVersion","datasetId":5037486},{"sourceId":8612418,"sourceType":"datasetVersion","datasetId":5075191},{"sourceId":158958765,"sourceType":"kernelVersion"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport keras\nimport keras.backend as K\nimport keras_cv\n\n\nimport librosa\nimport IPython.display as ipd\nimport librosa.display as lid\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport os, gc\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\nimport tensorflow as tf\nimport tensorflow_io as tfio\n\nprint('TensorFlow version =',tf.__version__)\n\n# USE MULTIPLE GPUS\ngpus = tf.config.list_physical_devices('GPU')\nif len(gpus)<=1: \n    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n    print(f'Using {len(gpus)} GPU')\nelse: \n    strategy = tf.distribute.MirroredStrategy()\n    print(f'Using {len(gpus)} GPUs')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-05T11:10:06.187443Z","iopub.execute_input":"2024-06-05T11:10:06.187997Z","iopub.status.idle":"2024-06-05T11:10:27.049396Z","shell.execute_reply.started":"2024-06-05T11:10:06.187892Z","shell.execute_reply":"2024-06-05T11:10:27.048214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmap = mpl.cm.get_cmap('coolwarm')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:10:27.051431Z","iopub.execute_input":"2024-06-05T11:10:27.052061Z","iopub.status.idle":"2024-06-05T11:10:27.058935Z","shell.execute_reply.started":"2024-06-05T11:10:27.052027Z","shell.execute_reply":"2024-06-05T11:10:27.057659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    \n    # Input image size and batch size\n    img_size = [48, 128, 321]\n    batch_size = 128\n    \n    # Audio duration, sample rate, and length\n    duration = 5 # second\n    sample_rate = 32000\n    audio_len = duration*sample_rate\n    \n    # STFT parameters\n    nfft = 2000\n    window = 2000\n    hop_length = 500\n    fmin = 40\n    fmax = 15000\n    \n    # Number of epochs, model name\n    epochs = 10\n    preset = 'efficientnetv2_b0_imagenet'\n    \n    # Data augmentation parameters\n    augment=False\n\n    # Class Labels for BirdCLEF 24\n    class_names = sorted(os.listdir('/kaggle/input/birdclef-2024/train_audio/'))\n    num_classes = len(class_names)\n    class_labels = list(range(num_classes))\n    label2name = dict(zip(class_labels, class_names))\n    name2label = {v:k for k,v in label2name.items()}","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:10:27.060664Z","iopub.execute_input":"2024-06-05T11:10:27.061476Z","iopub.status.idle":"2024-06-05T11:10:27.144178Z","shell.execute_reply.started":"2024-06-05T11:10:27.061437Z","shell.execute_reply":"2024-06-05T11:10:27.142934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/birdclef-2024'","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:10:27.147162Z","iopub.execute_input":"2024-06-05T11:10:27.147486Z","iopub.status.idle":"2024-06-05T11:10:27.152712Z","shell.execute_reply.started":"2024-06-05T11:10:27.147459Z","shell.execute_reply":"2024-06-05T11:10:27.151405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_paths = glob(f'{BASE_PATH}/test_soundscapes/*ogg')\n# During commit use `unlabeled` data as there is no `test` data.\n# During submission `test` data will automatically be populated.\nif len(test_paths)==0:\n    test_paths = glob(f'{BASE_PATH}/unlabeled_soundscapes/*ogg')[:129]\ntest_df = pd.DataFrame(test_paths, columns=['filepath'])\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:10:27.154079Z","iopub.execute_input":"2024-06-05T11:10:27.154392Z","iopub.status.idle":"2024-06-05T11:10:27.319585Z","shell.execute_reply.started":"2024-06-05T11:10:27.154366Z","shell.execute_reply":"2024-06-05T11:10:27.318412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_decoder1(with_labels=False, dim=CFG.audio_len):\n\n\n    def create_frames(audio, duration=5, sr=32000):\n        frame_size = int(duration * sr)\n        if np.shape(audio)[0] % frame_size != 0:\n            audio = np.pad(audio[..., None], [[0, frame_size - np.shape(audio)[0] % frame_size], [0, 0]]) # pad the end\n            audio = np.squeeze(audio) # remove extra dimension added for padding\n        frames = np.reshape(audio, [-1, frame_size]) # shape: [num_frames, frame_size]\n        return frames\n\n    def decode(path):\n        y, _ = librosa.load(path, sr=CFG.sample_rate)\n        y = librosa.util.normalize(y)\n        audio = np.array(create_frames(y))\n        l = []\n        for i in range(0,audio.shape[0]):\n            spec = librosa.feature.melspectrogram(\n                y=audio[i],\n                sr=CFG.sample_rate, # sample rate\n                n_fft=CFG.nfft, # number of samples in window \n                hop_length=CFG.hop_length, # step size of window\n                n_mels=CFG.img_size[1], # horizontal resolution from fminâ†’fmax in log scale\n                fmin=CFG.fmin, # minimum frequency\n                fmax=CFG.fmax, # maximum frequency\n                power=2.0, # intensity^power for log scale\n            )\n            # Convert to Db\n            spec = librosa.power_to_db(spec, ref=100)\n            # Normalize 0-min\n            spec = spec - spec.min()\n            # Normalize 0-255\n            spec = (spec / spec.max() * 255).astype(np.uint8)\n            l.append(spec)\n    \n        return l\n\n    return decode","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:10:27.321062Z","iopub.execute_input":"2024-06-05T11:10:27.32143Z","iopub.status.idle":"2024-06-05T11:10:27.334211Z","shell.execute_reply.started":"2024-06-05T11:10:27.321399Z","shell.execute_reply":"2024-06-05T11:10:27.332865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder=build_decoder1()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:10:27.335642Z","iopub.execute_input":"2024-06-05T11:10:27.336035Z","iopub.status.idle":"2024-06-05T11:10:27.349641Z","shell.execute_reply.started":"2024-06-05T11:10:27.336004Z","shell.execute_reply":"2024-06-05T11:10:27.34851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_specs = {}\nfor i in tqdm(range(len(test_df))):\n    if (i%100==0)&(i!=0): print(i,', ',end='')\n    row=test_df.iloc[i]\n    a=row.filepath\n    b=np.array(decoder(row.filepath))\n    \n    all_specs[a] = b","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:10:27.351075Z","iopub.execute_input":"2024-06-05T11:10:27.351515Z","iopub.status.idle":"2024-06-05T11:14:28.479471Z","shell.execute_reply.started":"2024-06-05T11:10:27.351477Z","shell.execute_reply":"2024-06-05T11:14:28.478286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row=test_df.iloc[0]\nb=np.array(decoder(row.filepath))\nprint(b.shape)\nplt.figure(figsize=(25, 10))\nlibrosa.display.specshow(b.reshape(b.shape[1],b.shape[0]*b.shape[2]), \n                         x_axis=\"time\", \n                         sr=CFG.sample_rate)\nplt.colorbar(format=\"%+2.f\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:14:28.481571Z","iopub.execute_input":"2024-06-05T11:14:28.482959Z","iopub.status.idle":"2024-06-05T11:14:32.312847Z","shell.execute_reply.started":"2024-06-05T11:14:28.482899Z","shell.execute_reply":"2024-06-05T11:14:32.311616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_decoder(with_labels=True):\n    def decode(filepath):\n        spec = all_specs[filepath]\n\n        spec = tf.tile(spec[..., None], [1, 1,1,3])\n        spec = tf.reshape(spec, [spec.shape[0],CFG.img_size[1],CFG.img_size[2], 3])\n        return spec\n    \n    return decode","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:14:32.316536Z","iopub.execute_input":"2024-06-05T11:14:32.316874Z","iopub.status.idle":"2024-06-05T11:14:32.32376Z","shell.execute_reply.started":"2024-06-05T11:14:32.316844Z","shell.execute_reply":"2024-06-05T11:14:32.322669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class build_dataset(tf.keras.utils.Sequence):\n    def __init__(self,filepath, batch_size=64, \n                  decode_fn=None, augment_fn=None,\n                  augment=False, shuffle=False):\n        self.filepaths = filepath\n        self.batch_size = batch_size \n        self.decode_fn = decode_fn\n        self.augment = augment \n        self.shuffle = shuffle \n        \n        if self.decode_fn is None:\n            self.decode_fn = build_decoder()\n            \n        self.on_epoch_end()\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = int( np.ceil((self.filepaths).shape[0] / self.batch_size ) )\n        return ct\n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        if self.augment: X = self.__augment_batch(X) \n        return X\n    \n    def __data_generation(self,indexes):\n        X = np.zeros((len(indexes),CFG.img_size[0],CFG.img_size[1],CFG.img_size[2],3),dtype='float32')\n        \n        for j,i in enumerate(indexes):\n            filepath = self.filepaths[i]\n            temp = self.decode_fn(filepath)\n            X[j,:temp.shape[0],:,:,:]= temp\n         \n        return X\n    \n    def __augment_batch(self, img_batch,y):\n        img_batch = self.augment_fn(img_batch)     \n        return img_batch\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange((self.filepaths).shape[0])\n        if self.shuffle: np.random.shuffle(self.indexes)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:14:32.325196Z","iopub.execute_input":"2024-06-05T11:14:32.325502Z","iopub.status.idle":"2024-06-05T11:14:32.340773Z","shell.execute_reply.started":"2024-06-05T11:14:32.325475Z","shell.execute_reply":"2024-06-05T11:14:32.33945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --find-links=/kaggle/input/tf-efficientnet-whl-files /kaggle/input/tf-efficientnet-whl-files/efficientnet-1.1.1-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:14:32.342451Z","iopub.execute_input":"2024-06-05T11:14:32.342887Z","iopub.status.idle":"2024-06-05T11:14:48.131086Z","shell.execute_reply.started":"2024-06-05T11:14:32.342846Z","shell.execute_reply":"2024-06-05T11:14:48.129645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.tfkeras as efn\n\ndef build_model():\n    \n    inp = tf.keras.Input(shape=(None,None,3))\n    base_model = efn.EfficientNetB0(include_top=False, weights=None, input_shape=None)\n    base_model.load_weights('/kaggle/input/tf-efficientnet-imagenet-weights/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')\n    x = base_model(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(CFG.num_classes,activation='sigmoid', dtype='float32')(x)\n        \n    # COMPILE MODEL\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    loss=tf.keras.losses.CategoricalCrossentropy()\n    metrics=[tf.keras.metrics.AUC(name='auc',multi_label=True,num_labels=CFG.num_classes)]\n    model.compile(loss=loss, optimizer = opt,metrics=metrics) \n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:14:48.132983Z","iopub.execute_input":"2024-06-05T11:14:48.133383Z","iopub.status.idle":"2024-06-05T11:14:48.211219Z","shell.execute_reply.started":"2024-06-05T11:14:48.133344Z","shell.execute_reply":"2024-06-05T11:14:48.210144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.load_weights('/kaggle/input/bird-clef-models/EffNet_v1_f1.weights.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:14:48.212587Z","iopub.execute_input":"2024-06-05T11:14:48.213821Z","iopub.status.idle":"2024-06-05T11:14:51.164269Z","shell.execute_reply.started":"2024-06-05T11:14:48.213787Z","shell.execute_reply":"2024-06-05T11:14:51.163134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\n\n# Initialize empty array to store predictions\npreds = np.empty(shape=(0, CFG.num_classes), dtype='float32')\n\n# Build test dataset\ntest_paths = test_df.filepath.tolist()\ntest_ds = build_dataset(test_df.filepath.values,batch_size=128)\n\n# Iterate over each audio file in the test dataset\nfor idx, specs in enumerate(tqdm(iter(test_ds), desc='test ', total=len(test_ds))):\n    # Extract the filename without the extension\n    \n    \n    print(specs.shape)\n    # Predict bird species for all frames in a recording using all trained models\n    frame_preds = []\n    for i in tqdm(range(specs.shape[1])):\n        frame_preds.append(model.predict(specs[:,i,:,:,:], verbose=0))\n    \n    # Create a ID for each frame in a recording using the filename and frame number\n    for i in range(idx*CFG.batch_size,(idx+1)*(CFG.batch_size)):\n        if i >= len(test_paths):\n            break\n        filename = test_paths[i].split('/')[-1].replace('.ogg','')\n        frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(frame_preds))]\n        ids += frame_ids\n        \n    frame_preds = np.array(frame_preds)\n    frame_preds = frame_preds.reshape((frame_preds.shape[0]*frame_preds.shape[1], \n                                       CFG.num_classes),order = 'F')\n    # Concatenate the ids\n    \n    # Concatenate the predictions\n    preds = np.concatenate([preds,(frame_preds)], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:14:51.166209Z","iopub.execute_input":"2024-06-05T11:14:51.167029Z","iopub.status.idle":"2024-06-05T11:18:23.292621Z","shell.execute_reply.started":"2024-06-05T11:14:51.166986Z","shell.execute_reply":"2024-06-05T11:18:23.291358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(ids)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:18:23.294141Z","iopub.execute_input":"2024-06-05T11:18:23.294494Z","iopub.status.idle":"2024-06-05T11:18:23.301851Z","shell.execute_reply.started":"2024-06-05T11:18:23.294463Z","shell.execute_reply":"2024-06-05T11:18:23.300815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:18:23.303237Z","iopub.execute_input":"2024-06-05T11:18:23.303575Z","iopub.status.idle":"2024-06-05T11:18:23.317564Z","shell.execute_reply.started":"2024-06-05T11:18:23.303546Z","shell.execute_reply":"2024-06-05T11:18:23.316335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds1=preds.copy()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:19:12.594997Z","iopub.execute_input":"2024-06-05T11:19:12.595413Z","iopub.status.idle":"2024-06-05T11:19:12.601161Z","shell.execute_reply.started":"2024-06-05T11:19:12.595383Z","shell.execute_reply":"2024-06-05T11:19:12.599868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.load_weights('/kaggle/input/bird-clef-models/EffNet_v1_f0.weights.h5')\nids = []\n\n# Initialize empty array to store predictions\npreds = np.empty(shape=(0, CFG.num_classes), dtype='float32')\n\n# Build test dataset\ntest_paths = test_df.filepath.tolist()\ntest_ds = build_dataset(test_df.filepath.values,batch_size=128)\n\n# Iterate over each audio file in the test dataset\nfor idx, specs in enumerate(tqdm(iter(test_ds), desc='test ', total=len(test_ds))):\n    # Extract the filename without the extension\n    \n    \n    print(specs.shape)\n    # Predict bird species for all frames in a recording using all trained models\n    frame_preds = []\n    for i in tqdm(range(specs.shape[1])):\n        frame_preds.append(model.predict(specs[:,i,:,:,:], verbose=0))\n    \n    # Create a ID for each frame in a recording using the filename and frame number\n    for i in range(idx*CFG.batch_size,(idx+1)*(CFG.batch_size)):\n        if i >= len(test_paths):\n            break\n        filename = test_paths[i].split('/')[-1].replace('.ogg','')\n        frame_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(frame_preds))]\n        ids += frame_ids\n        \n    frame_preds = np.array(frame_preds)\n    frame_preds = frame_preds.reshape((frame_preds.shape[0]*frame_preds.shape[1], \n                                       CFG.num_classes),order = 'F')\n    # Concatenate the ids\n    \n    # Concatenate the predictions\n    preds = np.concatenate([preds,(frame_preds)], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:19:12.917335Z","iopub.execute_input":"2024-06-05T11:19:12.918211Z","iopub.status.idle":"2024-06-05T11:22:44.855978Z","shell.execute_reply.started":"2024-06-05T11:19:12.918172Z","shell.execute_reply":"2024-06-05T11:22:44.854895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:22:44.858278Z","iopub.execute_input":"2024-06-05T11:22:44.859109Z","iopub.status.idle":"2024-06-05T11:22:44.866914Z","shell.execute_reply.started":"2024-06-05T11:22:44.859066Z","shell.execute_reply":"2024-06-05T11:22:44.865791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = pd.DataFrame(ids, columns=['row_id'])\npred_df.loc[:, CFG.class_names] = (preds+preds1)/2\npred_df.to_csv('submission.csv',index=False)\npred_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:22:44.882572Z","iopub.execute_input":"2024-06-05T11:22:44.883002Z","iopub.status.idle":"2024-06-05T11:22:47.123617Z","shell.execute_reply.started":"2024-06-05T11:22:44.882893Z","shell.execute_reply":"2024-06-05T11:22:47.122513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}